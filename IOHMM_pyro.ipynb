{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch\n",
    "from torch import nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer.autoguide import AutoDelta, AutoNormal\n",
    "from pyro.nn import PyroSample, PyroParam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_probs(logits):\n",
    "    return torch.exp(logits - torch.logsumexp(logits, dim=-1, keepdim=True))\n",
    "\n",
    "class IOHMM_model:\n",
    "    def __init__(self, num_states, inputs, outputs, max_iter, tol,\n",
    "                 initial_pi=None, theta_transition=None, theta_emission=None, sd=None):\n",
    "    \n",
    "        self.num_states = num_states\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.T = inputs.shape[0]\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.history = []\n",
    "\n",
    "        # Initialize parameters\n",
    "        self.initial_pi = torch.ones(num_states) / num_states if initial_pi is None else initial_pi\n",
    "        self.theta_transition = torch.randn(num_states, num_states, inputs.shape[1] + 1) if theta_transition is None else theta_transition\n",
    "        self.theta_emission = torch.randn(num_states, inputs.shape[1] + 1) if theta_emission is None else theta_emission\n",
    "        self.sd = torch.ones(num_states, self.T) if sd is None else sd\n",
    "        #self.theta_transition = pyro.param('theta_transition', torch.randn(num_states, num_states, inputs.shape[1] + 1))\n",
    "        #self.theta_emission = pyro.param('theta_emission', torch.randn(num_states, inputs.shape[1] + 1))\n",
    "        #self.sd = pyro.param('sd', torch.ones(num_states, self.T), constraint=dist.constraints.positive)\n",
    "        #self.initial_pi = pyro.param('initial_pi', torch.ones(num_states) / num_states, constraint=dist.constraints.simplex)\n",
    "\n",
    "\n",
    "    def model(self, inputs, outputs):\n",
    "        \n",
    "        # Initial state distribution\n",
    "        z = pyro.sample('z_0', dist.Categorical(probs=self.initial_pi))\n",
    "\n",
    "        for t in range(self.T):\n",
    "            # Emission model\n",
    "            emission_mean = torch.matmul(self.theta_emission[z], torch.cat((torch.ones(1), inputs[t, :])).unsqueeze(-1)).squeeze()\n",
    "            sd = self.sd[z,t].exp()\n",
    "            pyro.sample(f'obs_{t}', dist.Normal(emission_mean, sd), obs=outputs[t])\n",
    "\n",
    "            if t < self.T - 1:\n",
    "                # Transition model\n",
    "                logits = torch.matmul(self.theta_transition[z], torch.cat((torch.ones(1), inputs[t, :])).unsqueeze(-1)).squeeze()\n",
    "                transition_probs = logits_to_probs(logits)\n",
    "                z = pyro.sample(f'z_{t+1}', dist.Categorical(probs=transition_probs))\n",
    "\n",
    "    def guide(self, inputs, outputs):\n",
    "        # Variational parameters for the initial state distribution\n",
    "        q_initial_pi = pyro.param('q_initial_pi', self.initial_pi, constraint=dist.constraints.simplex)\n",
    "        q_z = pyro.sample('z_0', dist.Categorical(probs=q_initial_pi))\n",
    "\n",
    "        q_theta_transition = pyro.param('q_theta_transition', self.theta_transition)\n",
    "        q_theta_emission = pyro.param('q_theta_emission', self.theta_emission)\n",
    "        q_sd = pyro.param('q_sd', self.sd, constraint=dist.constraints.positive)\n",
    "\n",
    "\n",
    "        for t in range(self.T - 1):\n",
    "            logits = torch.matmul(q_theta_transition[q_z], torch.cat((torch.ones(1), inputs[t, :])))\n",
    "            transition_probs = logits_to_probs(logits)\n",
    "            q_z = pyro.sample(f'z_{t+1}', dist.Categorical(probs=transition_probs))\n",
    "\n",
    "    def fit(self):\n",
    "        optimizer = Adam({\"lr\": 0.01})\n",
    "        svi = SVI(self.model, self.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "        for step in range(self.max_iter):\n",
    "            loss = svi.step(self.inputs, self.outputs)\n",
    "            \n",
    "            self.initial_pi = pyro.param('q_initial_pi')\n",
    "            self.theta_emission = pyro.param('q_theta_emission')\n",
    "            self.theta_transition = pyro.param('q_theta_transition')\n",
    "            self.sd = pyro.param('q_sd')\n",
    "\n",
    "            self.history.append(loss)\n",
    "            if step % 10 == 0:\n",
    "                print(f\"Step {step}: loss = {loss}\")\n",
    "            if step > 0 and abs(self.history[-1] - self.history[-2]) < self.tol:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/vfdk9pcj66g2trgt19fh08480000gn/T/ipykernel_41664/2553795691.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  input = torch.tensor([x, diff], dtype=torch.float32).T\n"
     ]
    }
   ],
   "source": [
    "x=np.arange(np.pi/2 , 11*np.pi/2, 0.1)\n",
    "x=np.sin(x)\n",
    "x_shift = x[:-1]\n",
    "x = x[1:]\n",
    "diff = x - x_shift\n",
    "\n",
    "hidden_states = [0 if diff[i] > 0 else 1 for i in range(len(diff))]\n",
    "y = [x[i] + np.random.normal(0.5,0.1) if hidden_states[i]==0 else x[i] - np.random.normal(0.5,0.1) for i in range(len(x))]\n",
    "\n",
    "input = torch.tensor([x, diff], dtype=torch.float32).T\n",
    "output = torch.tensor(y, dtype=torch.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_transition\n",
      "tensor([[[ 0.0288, -0.5775, -0.0028],\n",
      "         [ 1.1988,  1.3219, -0.0804]],\n",
      "\n",
      "        [[-0.7637, -0.2766, -0.0684],\n",
      "         [ 0.1273, -0.3001, -1.1393]]])\n",
      "theta_emission\n",
      "tensor([[ 1.3791,  0.2689,  1.8250],\n",
      "        [-0.9837, -0.6596, -0.3291]])\n",
      "initial_pi\n",
      "tensor([0.5000, 0.5000])\n"
     ]
    }
   ],
   "source": [
    "num_states = 2\n",
    "max_iter = 1000\n",
    "tol = 1e-4\n",
    "\n",
    "iohmm = IOHMM_model(num_states, input, output, max_iter, tol)\n",
    "print(\"theta_transition\")\n",
    "print(iohmm.theta_transition)\n",
    "print(\"theta_emission\")\n",
    "print(iohmm.theta_emission)\n",
    "print(\"initial_pi\")\n",
    "print(iohmm.initial_pi)\n",
    "#print(iohmm.sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([157, 2])\n"
     ]
    }
   ],
   "source": [
    "print(iohmm.theta_emission.shape)\n",
    "print(iohmm.inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss = 331.61166620254517\n",
      "Step 10: loss = 322.52592515945435\n",
      "Step 20: loss = 311.47847509384155\n",
      "Step 30: loss = 298.66763496398926\n",
      "Step 40: loss = 288.28627943992615\n",
      "Step 50: loss = 277.9204510450363\n",
      "Step 60: loss = 268.7274281978607\n",
      "Step 70: loss = 259.3067419528961\n",
      "Step 80: loss = 250.61321687698364\n",
      "Step 90: loss = 243.62178218364716\n",
      "Step 100: loss = 235.9726848602295\n",
      "Step 110: loss = 231.3232283592224\n",
      "Step 120: loss = 221.70822954177856\n",
      "Step 130: loss = 217.27923381328583\n",
      "Step 140: loss = 215.9348382949829\n",
      "Step 150: loss = 209.93115484714508\n",
      "Step 160: loss = 206.23529875278473\n",
      "Step 170: loss = 203.8552144765854\n",
      "Step 180: loss = 200.47974574565887\n",
      "Step 190: loss = 198.9700504541397\n",
      "Step 200: loss = 195.9186553955078\n",
      "Step 210: loss = 194.19640910625458\n",
      "Step 220: loss = 192.92591607570648\n",
      "Step 230: loss = 191.32984459400177\n",
      "Step 240: loss = 188.78779554367065\n",
      "Step 250: loss = 186.92579889297485\n",
      "Step 260: loss = 185.91550481319427\n",
      "Step 270: loss = 183.95980834960938\n",
      "Step 280: loss = 182.82135665416718\n",
      "Step 290: loss = 181.7188755273819\n",
      "Step 300: loss = 180.20656085014343\n",
      "Step 310: loss = 179.73910987377167\n",
      "Step 320: loss = 177.98224222660065\n",
      "Step 330: loss = 176.21492463350296\n",
      "Step 340: loss = 175.9972186088562\n",
      "Step 350: loss = 174.92842066287994\n",
      "Step 360: loss = 173.71873992681503\n",
      "Step 370: loss = 173.47606521844864\n",
      "Step 380: loss = 172.37651926279068\n",
      "Step 390: loss = 172.05920952558517\n",
      "Step 400: loss = 170.79582697153091\n",
      "Step 410: loss = 170.30303978919983\n",
      "Step 420: loss = 169.50128936767578\n",
      "Step 430: loss = 168.79352962970734\n",
      "Step 440: loss = 168.64836031198502\n",
      "Step 450: loss = 167.95931732654572\n",
      "Step 460: loss = 166.77129566669464\n",
      "Step 470: loss = 166.37658190727234\n",
      "Step 480: loss = 166.34016174077988\n",
      "Step 490: loss = 165.37779700756073\n",
      "Step 500: loss = 165.16703182458878\n",
      "Step 510: loss = 164.79532903432846\n",
      "Step 520: loss = 164.11301881074905\n",
      "Step 530: loss = 164.34943908452988\n",
      "Step 540: loss = 162.85998463630676\n",
      "Step 550: loss = 162.96062350273132\n",
      "Step 560: loss = 162.2964345216751\n",
      "Step 570: loss = 162.41087347269058\n",
      "Step 580: loss = 161.52933484315872\n",
      "Step 590: loss = 161.54890036582947\n",
      "Step 600: loss = 161.16031807661057\n",
      "Step 610: loss = 161.2771223783493\n",
      "Step 620: loss = 160.5898272395134\n",
      "Step 630: loss = 161.0731059908867\n",
      "Step 640: loss = 160.26283878087997\n",
      "Step 650: loss = 159.60930448770523\n",
      "Step 660: loss = 159.87612396478653\n",
      "Step 670: loss = 159.69808197021484\n",
      "Step 680: loss = 159.12850445508957\n",
      "Step 690: loss = 159.0324386358261\n",
      "Step 700: loss = 158.92654502391815\n",
      "Step 710: loss = 158.64309298992157\n",
      "Step 720: loss = 158.81722509860992\n",
      "Step 730: loss = 158.408682346344\n",
      "Step 740: loss = 158.20240104198456\n",
      "Step 750: loss = 157.9767147898674\n",
      "Step 760: loss = 157.60764342546463\n",
      "Step 770: loss = 157.61140888929367\n",
      "Step 780: loss = 157.43854451179504\n",
      "Step 790: loss = 157.02387821674347\n",
      "Step 800: loss = 157.13829290866852\n",
      "Step 810: loss = 156.92659831047058\n",
      "Step 820: loss = 156.54690086841583\n",
      "Step 830: loss = 156.42349207401276\n",
      "Step 840: loss = 156.41333359479904\n",
      "Step 850: loss = 156.1168111562729\n",
      "Step 860: loss = 155.88155883550644\n",
      "Step 870: loss = 155.9631149172783\n",
      "Step 880: loss = 156.17941015958786\n",
      "Step 890: loss = 155.55845499038696\n",
      "Step 900: loss = 155.50941318273544\n",
      "Step 910: loss = 155.7658615708351\n",
      "Step 920: loss = 155.3752445578575\n",
      "Step 930: loss = 155.19084817171097\n",
      "Step 940: loss = 155.224167406559\n",
      "Step 950: loss = 155.1338456273079\n",
      "Step 960: loss = 155.0940015912056\n",
      "Step 970: loss = 154.69550555944443\n",
      "Step 980: loss = 154.614650785923\n",
      "Step 990: loss = 154.85000264644623\n"
     ]
    }
   ],
   "source": [
    "iohmm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_transition\n",
      "tensor([[[-0.3876, -0.2650,  0.3232],\n",
      "         [ 1.6152,  1.0093, -0.4064]],\n",
      "\n",
      "        [[-0.5064, -0.7262, -0.0456],\n",
      "         [-0.1300,  0.1495, -1.1621]]], requires_grad=True)\n",
      "theta_emission\n",
      "tensor([[ 4.2261e-03,  1.0215e+00,  6.3538e+00],\n",
      "        [-9.4851e-04,  9.9401e-01,  6.2670e+00]], requires_grad=True)\n",
      "initial_pi\n",
      "tensor([0.6557, 0.3443], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# inspecting the learned parameters\n",
    "print(\"theta_transition\")\n",
    "print(iohmm.theta_transition)\n",
    "print(\"theta_emission\")\n",
    "print(iohmm.theta_emission)\n",
    "print(\"initial_pi\")\n",
    "print(iohmm.initial_pi)\n",
    "#print(iohmm.sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final q_initial_pi: [0.6556922 0.3443078]\n"
     ]
    }
   ],
   "source": [
    "q_initial_pi_value = pyro.param('q_initial_pi').detach().cpu().numpy()\n",
    "print(f\"Final q_initial_pi: {q_initial_pi_value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
